{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Timeseries-Analysis-Using-Gaussian-Process-Regression\" data-toc-modified-id=\"Timeseries-Analysis-Using-Gaussian-Process-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Timeseries Analysis Using Gaussian Process Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Background</a></span></li></ul></li><li><span><a href=\"#2.-GP-Regression-Example\" data-toc-modified-id=\"2.-GP-Regression-Example-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2. GP Regression Example</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Periodicity-estimation-using-Gaussian-Process-Regression\" data-toc-modified-id=\"Periodicity-estimation-using-Gaussian-Process-Regression-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Periodicity estimation using Gaussian Process Regression</a></span></li></ul></li></ul></li><li><span><a href=\"#3.-Results\" data-toc-modified-id=\"3.-Results-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>3. Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1.-Oscillations-in-Cloud-Size-Distribution\" data-toc-modified-id=\"3.1.-Oscillations-in-Cloud-Size-Distribution-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>3.1. Oscillations in Cloud Size Distribution</a></span></li></ul></li><li><span><a href=\"#4.-References\" data-toc-modified-id=\"4.-References-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>4. References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries Analysis Using Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A *Gaussian Process* is *a collection of random variables, any finite number of which have a joint Gaussian distribution*.\n",
    " \n",
    " A Gaussian process is completely specified by its mean function and covariance function. The mean function $m(\\boldsymbol{x})$ reflects the expected function value at imput $\\boldsymbol{x}$: $$m(\\boldsymbol{x}) = \\mathbb{E}[f(\\boldsymbol{x})],$$ that is, the average of all functions in the distribution evaluated at input $\\boldsymbol{x}$. The prior mean is often set to $m(\\boldsymbol{x}) = 0$ in order to avoid expensive posterior computations and only do inference via the covariance function. The covariance function $k(\\boldsymbol{x}, \\boldsymbol{x'})$ models the dependence between the fuction values at different input points $\\boldsymbol{x}$ and $\\boldsymbol{x'}$: $$k(\\boldsymbol{x}, \\boldsymbol{x'}) = \\mathbb{E}[(f(\\boldsymbol{x}) - m(\\boldsymbol{x}))(f(\\boldsymbol{x'}) - m(\\boldsymbol{x'}))]$$ and we can finally write the *Gaussian process* as $$f(\\boldsymbol{x}) \\approx \\mathcal{GP}(m(\\boldsymbol{x}), k(\\boldsymbol{x}, \\boldsymbol{x'})).$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A simple example of a Gaussian process can be obtained from a Bayesian linear regression model $f(\\boldsymbol{x}) = \\phi(\\boldsymbol{x})^\\intercal \\boldsymbol{w}$ with prior $\\boldsymbol{w} \\approx \\mathcal{N}(0, \\sigma_p)$. Then the mean and the covariance of the model can be written as $$\\mathbb{E}[f(\\boldsymbol{x})] = \\phi(\\boldsymbol{x})^\\intercal \\mathbb{E}[\\boldsymbol{w}] = 0,$$ $$\\mathbb{E}[f(\\boldsymbol{x})f(\\boldsymbol{x'})] = \\phi(\\boldsymbol{x})^\\intercal \\mathbb{E}[\\boldsymbol{w}\\boldsymbol{w}^\\intercal] \\phi(\\boldsymbol{x'}) = \\phi(\\boldsymbol{x})^\\intercal \\sigma_p \\phi(\\boldsymbol{x'}).$$\n",
    " \n",
    " Thus $f(\\boldsymbol{x})$ and $f(\\boldsymbol{x'})$ are jointly Gaussian with $0$ mean and covariance given by the second equation above. The covariance between pairs of random variables is specified by the aptly named *covariance function* $k(\\boldsymbol{x}, \\boldsymbol{x'})$. The symbol $k(\\boldsymbol{x}, \\boldsymbol{x'})$ is because the covariance function is often referred to as the *kernel*. We will use the two terms interchangeably.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The most popular choice of a kernel is the *radial-basis function* kernel, also called the *squared exponential* (SE) kernel, $$k(x_i, x_j) = \\exp \\left( - \\frac{1}{2} \\left( \\frac{(x_i - x_j)}{l} \\right)^2 \\right) \\,,$$ which is parameterized by a length-scale parameter $l < 0$. Sometimes it is called the *Gaussian* kernel, although I find it a bit confusing at times. It is by far the most widely used covariance function in the machine learning studies, and is infinitely differentiable and very smooth. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be using the *periodic* kernel, \n",
    " \n",
    " $$k(x_i, x_j) = -2 \\frac{\\sin^2 (\\pi | x_i - x_j|/T)}{l^2}  \\,,$$ \n",
    " \n",
    "which is parameterized by a decay scale $l > 0$ and a periodicity $T > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " Also, we will also be using the *rational quadratic* (RQ) kernel \n",
    " \n",
    " $$k(x_i, x_j) = \\left( 1 - \\frac{(x_i - x_j)^2}{2 \\alpha l^2} \\right)^{-\\alpha} \\,,$$ \n",
    " \n",
    "where an additional *scale mixture* parameter $\\alpha > 0$ is used to construct an infinite sum (mixture) of SE kernels at different length scales. The RQ covariance function becomes the SE covariance function with a length scale of $l$ for $\\alpha \\to \\infty$.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In order to make predictions given the covariance function(s), we can draw outputs for a finite number of points by using a multivariate Gaussian distribution with a covariance matrix generated by the kernel. Let $\\boldsymbol{X_*}$ be a matrix with on each row a new input point $\\boldsymbol{x}^*_i$ for an arbitrary $i$. Then the covariances between all inputs in $\\boldsymbol{X_*}$ corresponds to: \n",
    " \n",
    " $$K(\\boldsymbol{X_*}, \\boldsymbol{X_*}) = \n",
    "    \\begin{bmatrix}\n",
    "        k(\\boldsymbol{x^*_1}, \\boldsymbol{x^*_1}) & k(\\boldsymbol{x^*_1}, \\boldsymbol{x^*_2}) & \\dots & k(\\boldsymbol{x^*_1}, \\boldsymbol{x^*_n}) \\\\ \n",
    "        k(\\boldsymbol{x^*_2}, \\boldsymbol{x^*_1}) & k(\\boldsymbol{x^*_2}, \\boldsymbol{x^*_2}) & \\dots & k(\\boldsymbol{x^*_2}, \\boldsymbol{x^*_n}) \\\\\n",
    "        \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "        k(\\boldsymbol{x^*_n}, \\boldsymbol{x^*_1}) & k(\\boldsymbol{x^*_n}, \\boldsymbol{x^*_2}) & \\dots & k(\\boldsymbol{x^*_n}, \\boldsymbol{x^*_n})\n",
    "    \\end{bmatrix}.$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    " We can now sample the values of $f$ at each set of input points $\\boldsymbol{X_*}$ from the $\\mathcal{GP}$ by sampling from a multivariate normal distribution $$\\boldsymbol{f_*} \\sim \\mathcal{N}(0, K(\\boldsymbol{X_*}, \\boldsymbol{X_*}))$$ where $\\boldsymbol{f_*} = [f(\\boldsymbol{x^*_1}), \\dots, f(\\boldsymbol{x^*_n})]^\\intercal$, where $\\boldsymbol{f_*}$ is a sample from the distribution of functions evaluated at the corresponding input point.\n",
    " \n",
    " Suppose we have made a series of noisy observations $y = f(\\boldsymbol{x}) + \\epsilon)$ for some observational noise $\\epsilon$. Assuming $\\epsilon \\approx \\mathcal{N}(0, \\sigma^2_n)$, the prior for these observations becomes $$\\text{cov}(\\boldsymbol{y}) = K(X, X) + \\delta^2_n I.$$ \n",
    " \n",
    " Then the joint distribution of the training outputs $\\boldsymbol{f}$ and the test outputs $\\boldsymbol{f_*}$ according to the prior is \n",
    " $$\n",
    " \\begin{bmatrix}\n",
    "     \\boldsymbol{y_t} \\\\ \\boldsymbol{f_*}\n",
    " \\end{bmatrix} = \\mathcal{N} \\left( 0,\n",
    " \\begin{bmatrix}\n",
    "     K(\\boldsymbol{X_t}, \\boldsymbol{X_t}) + \\sigma^2_n & K(\\boldsymbol{X_t}, \\boldsymbol{X_*}) \\\\\n",
    "     K(\\boldsymbol{X_*}, \\boldsymbol{X_t}) & K(\\boldsymbol{X_*}, \\boldsymbol{X_*})\n",
    " \\end{bmatrix} \\right)\n",
    " $$ where $K(\\boldsymbol{X_t}, \\boldsymbol{X_t})$ is the covariance between all observed points (or training points), $K(\\boldsymbol{X_t}, \\boldsymbol{X_*})$ is the covariance between the new observations, $K(\\boldsymbol{X_*}, \\boldsymbol{X_t})$ is the covariance between the new and old observations, and finally, $K(\\boldsymbol{X_*}, \\boldsymbol{X_*}$ is the covariance between old and new observed points.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The conditional distribution is then $$\\boldsymbol{f_*} \\; \\mid \\; X_t, \\boldsymbol{y_t}, X_* \\approx \\mathcal{N}(\\overline{\\boldsymbol{f}}_*, \\text{cov}(\\boldsymbol{f_*})),$$ where $$\\overline{\\boldsymbol{f}}_* \\triangleq \\mathbb{E}[\\boldsymbol{f_*} \\mid X_t, \\boldsymbol{y}, X_*] = K(\\boldsymbol{X_*}, \\boldsymbol{X_t})[K(\\boldsymbol{X_t}, \\boldsymbol{X_t}) + \\delta^2_n I]^{-1} \\boldsymbol{y},$$ $$\\text{cov}(\\boldsymbol{f_*}) = K(\\boldsymbol{X_*}, \\boldsymbol{X_*}) - K(\\boldsymbol{X_*}, \\boldsymbol{X_t})[K(\\boldsymbol{X_t}, \\boldsymbol{X_t}) + \\delta^2_n I]^{-1} K(\\boldsymbol{X_t}, \\boldsymbol{X_*}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " This posterior is also a Gaussian process with mean $$m(\\boldsymbol{x}) = K(\\boldsymbol{x}, \\boldsymbol{X_t})[K(\\boldsymbol{X_t}, \\boldsymbol{X_t}) + \\delta^2_n I]^{-1} \\boldsymbol{y_t},$$ and kernel $$k_t(\\boldsymbol{x}, \\boldsymbol{x'}) = k(\\boldsymbol{x}, \\boldsymbol{x'})- K(\\boldsymbol{x}, \\boldsymbol{X_t})[K(\\boldsymbol{X_t}, \\boldsymbol{X_t}) + \\delta^2_n I]^{-1} K(\\boldsymbol{X_t}, \\boldsymbol{x'}).$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that for noise-free observations, we can simply omit $\\delta^2_n I$ term from above. The two cases will have the solutions of the same shape.\n",
    " \n",
    " Therefore, having made the initial observations (on *training sets*) and received new observations, we can calculate the four covariance matrices $K(\\boldsymbol{X_t}, \\boldsymbol{X_t}) + \\sigma^2_n$, $K(\\boldsymbol{X_t}, \\boldsymbol{X_*})$, $K(\\boldsymbol{X_*}, \\boldsymbol{X_t})$ and $K(\\boldsymbol{X_*}, \\boldsymbol{X_*})$ to obtain posterior distribution and its kernel. The kernel is usually defined by a few hyperparameters that are inferred from, and only from, the data. For this reason, the bulk of GP regression method is to construct the kernel from possibly a number of covariance functions (in order to encode the prior assumptions about the observation), and obtaining the hyperparameters from the observations. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since this is often very challenging, in a real-world scenario, the hyperparameters are obtained by maximizing the (log) marginal likelihood. This is similar to parameter estimatiom by maximum likelihood and is also referred to as type-II maximum likelihood. The log marginal likelihood is defined as $$ \\log{p}(\\boldsymbol{y} \\mid \\boldsymbol{X}) = - \\frac{1}{2} \\boldsymbol{y}^\\intercal \\boldsymbol{K}^{-1}_y \\boldsymbol{y} - \\frac{1}{2} \\log{| \\boldsymbol{K}_y |} - \\frac{n}{2} \\log{2 \\pi},$$ where $K_y = K(\\boldsymbol{X_t}, \\boldsymbol{X_t}) + \\sigma^2_n I$. The first term measures how well the current kernel reproduces $\\boldsymbol{y}$, the second term measures the complexity of the model, and the last term is a constant used for normalization. Often (and it is the case for *scikit-learn*) the log marginal likelihood is maximized using a gradient-descent optimization, which is based on the partial derivative of the log marginal likelihood with respect to $\\theta$ (i.e. the hyperparameters of the covariance functions, such as the length scale $l$). That is,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\n",
    "\\begin{align} \n",
    "\\frac{\\partial}{\\partial \\theta_i} \\log{p(\\boldsymbol{y} \\mid X, \\boldsymbol{\\theta})} &= \\frac{1}{2} \\boldsymbol{y}^\\intercal \\boldsymbol{K}^{-1}_y \\boldsymbol{y} - \\frac{1}{2} \\text{tr} \\left( \\boldsymbol{K}^{-1}_y \\frac{\\partial \\boldsymbol{K}^{-1}_y}{\\partial \\theta_i} \\right) \\\\\n",
    "&= \\frac{1}{2} \\text{tr} \\left( (\\boldsymbol{K}^{-1}_y \\boldsymbol{y}) (\\boldsymbol{K}^{-1}_y \\boldsymbol{y})^\\intercal) - \\boldsymbol{K}^{-1}_y) \\frac{\\partial \\boldsymbol{K}^{-1}_y}{\\partial \\theta_i} \\right)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ExpSineSquared, RationalQuadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Plot settings\n",
    "sns.set_context('paper')\n",
    "sns.set_style('ticks', \n",
    "    {\n",
    "        'axes.grid': False, \n",
    "        'axes.linewidth': '0.75',\n",
    "        'grid.color': '0.75',\n",
    "        'grid.linestyle': u':',\n",
    "        'legend.frameon': True,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2. GP Regression Example\n",
    " ### Periodicity estimation using Gaussian Process Regression\n",
    "\n",
    " First, we will use a known periodic timeseries \n",
    " \n",
    " $$y(t) = \\sin \\left (\\frac{2 \\pi}{T} t \\right)$$ \n",
    " \n",
    " as an example, where $t$ is time and $T$ is period of oscillation (both in minutes, for simplicity). To make this example more interesting for the sake of Gaussian process regression, we will also add a moderately increasing long-term trend to our timeseries observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(1, figsize=(15, 5))\n",
    "\n",
    "xi = np.linspace(0, 40, 120)\n",
    "y = np.sin(xi * (2 * np.pi) / 10) + xi / 10\n",
    "\n",
    "plt.plot(xi, y, lw=4, alpha=0.3)\n",
    "\n",
    "plt.xlim([0, 60])\n",
    "fig.savefig('../png/raw_simple.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then we add random observational errors to the timeseries data above. For this purpose, we use Numpy's random number generater sampled from a normal distribution of mean $0$ and variance $0.1$ in $x$ and 1 in $y$. This is more or less for simplicity, and repeating the experiment with different samplers (from different probability distributions) does not appear to affect the accuracy of the result.\n",
    " \n",
    " The errors are added in both dimensions, resulting in $$y(t) = \\frac{2 \\pi}{T} (t + \\epsilon_t) + \\epsilon.$$ The observationals errors $\\epsilon$ and $\\epsilon_t$ can be interpreted as sampling errors, but for this example, I aim to have the magnitude of these errors arbitarily large enough to make it difficult to see the underlying trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with random error (in both x and y)\n",
    "fig = plt.figure(1, figsize=(15, 5))\n",
    "\n",
    "x_e = xi + np.random.randn(len(xi)) / 10\n",
    "y_e = y + np.random.randn(len(y))\n",
    "\n",
    "plt.plot(xi, y, lw=4, alpha=0.3)\n",
    "plt.plot(x_e, y_e, 'ko', alpha=0.5)\n",
    "plt.plot(x_e, y_e, 'ko--', alpha=0.2)\n",
    "\n",
    "plt.xlim([0, 60])\n",
    "fig.savefig('../png/sine_plus_noise.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " While the above plot makes the underlying oscillation somewhat obvious, it is very difficult to see that without knowing the original timeseires distribution. If we are given the following distribution, I'd say we will probably attempt to approximate it with a linear regression, seeing that, by observation, I would highly doubt if there are any oscillatory motions in the observed timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(15, 5))\n",
    "\n",
    "plt.plot(x_e, y_e, 'ko', alpha=0.5)\n",
    "plt.plot(x_e, y_e, 'ko--', alpha=0.2)\n",
    "\n",
    "plt.xlim([0, 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, we use Gaussian process regression module from *scikit-learn* to identify the underlying oscillation in our timeseries. Obviously, we will be using a periodic kernel, $$k(x_i, x_j) = \\exp \\left(-2 \\frac{\\sin^2 \\left(\\frac{\\pi}{T} d(x_i, x_j) \\right)}{l^2} \\right) \\,,$$ which is parameterized by a length scale $l > 0$ and a periodicity $T > 0$.\n",
    " \n",
    " We will also be using a radial-basis function kernel, also called the *squared exponential* (SE) kernel, $$k(x_i, x_j) = \\exp \\left( - \\frac{1}{2} d \\left( \\frac{x_i}{l}, \\frac{x_j}{l} \\right) \\right) \\,,$$ which is parameterized by a length-scale parameter $l < 0$. In this case, the SE kernel is used to account for the small increasing trend observed in our timeseries. However, the choice of the SE kernel isn't deliberate, but it is mainly because the SE kernel is most widely used for GP regression and the smooth nature of the covariance function is useful in this case.\n",
    " \n",
    " Lastly, to account for local variability, we will use the *rational quadratic* (RQ) kernel $$k(x_i, x_j) = \\left( 1 - \\frac{d(x_i, x_j)^2}{2 \\alpha l^2} \\right)^{-\\alpha} \\,,$$ where an additional *scale mixture* parameter $\\alpha > 0$ is used to construct an infinite sum (mixture) of SE kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kernel = 1.0 * RBF(length_scale=1e1, length_scale_bounds=(1e-1, 1e3)) \\\n",
    "        + 1.0 * RationalQuadratic(alpha=1e1, alpha_bounds=(1e-2, 1e3), length_scale=1e-1, length_scale_bounds=(1e-5, 1)) \\\n",
    "        + 1.0 * WhiteKernel(noise_level=1e-5) \\\n",
    "        + 1.0 * ExpSineSquared(length_scale_bounds=(1e-2, 1e2), periodicity_bounds=(5, 30))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "X_ = np.array(x_e)\n",
    "gp.fit(X_[:, None], np.array(y_e))\n",
    "\n",
    "fig = plt.figure(1, figsize=(15, 5))\n",
    "\n",
    "X = np.linspace(0, 80, 240)\n",
    "y_mean, y_std = gp.predict(X[:, None], return_std=True)\n",
    "plt.plot(X, y_mean, 'k', lw=1, zorder=9)\n",
    "plt.fill_between(X, y_mean - y_std, y_mean + y_std,\n",
    "                 alpha=0.2, color='k')\n",
    "print('kernel dump: ',gp.kernel_)\n",
    "\n",
    "y_samples = gp.sample_y(X[:, None], 5)\n",
    "plt.plot(X, y_samples, lw=0.5, alpha=0.8)\n",
    "\n",
    "plt.plot(xi, y, lw=4, alpha=0.3)\n",
    "plt.plot(x_e, y_e, 'ko', alpha=0.5)\n",
    "plt.plot(x_e, y_e, 'ko--', alpha=0.2)\n",
    "\n",
    "plt.xlim([0, 60])\n",
    "plt.ylim([-2, 6])\n",
    "fig.savefig('../png/process_prediction_simple.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The above plot shows the results of applying Gaussian process regression using *scikit-learn* on our observed timeseries data. The black dots show the timeseries data points, the grey regions denotes the uncertainties involved with the regression, and the coloured lines show a few prior functions. The solid black line is the mean value of such prior functions, which is our *posterior distribution* over fuctions. \n",
    " \n",
    " Notice that the uncertainties are reduced closer to some of the observations, but not fully because we believe that the observations are not the exact truth. This gives us quite a bit of flexibility with building the *posterior* distribution, which consists our prediction model through inferenece.\n",
    " \n",
    " As we can see from the hyperparameters of the posterior distribution (solid black line), GP regression method has dont a good job at retrieving the underlying oscillatory motion with periodicity $T = 9.9 \\approx 10$. \n",
    " \n",
    " However, it is evident that past the training dataset ($t > 40$ minutes), the predicted model fails at reproducing the long-term increasing trend in our timeseries data. It is possible to further optimize the hyperparameters and get a better model, but for the sake of this example, we choose to keep things simple and focused on our goal, which is to estimate the periodicity in a noisy timeseries data as precisely as possible.\n",
    " \n",
    " For that purpose, we can de-trend the observed timeseries to remove any long-term increasing (or decreasing) trend. The following figure shows the result of apply GP regression on the de-trended timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * RationalQuadratic(alpha_bounds=(1e-2, 1e3), length_scale=1e-1, length_scale_bounds=(1e-5, 1e1)) \\\n",
    "        + 1.0 * WhiteKernel(noise_level=1e-2) \\\n",
    "        + 1.0 * ExpSineSquared(length_scale_bounds=(1e-1, 1e2), periodicity_bounds=(5, 30))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "\n",
    "y_d = signal.detrend(y)\n",
    "y_derr = signal.detrend(y_e)\n",
    "\n",
    "X_ = np.array(x_e)\n",
    "gp.fit(X_[:, None], np.array(y_derr))\n",
    "\n",
    "fig = plt.figure(1, figsize=(15, 5))\n",
    "\n",
    "X = np.linspace(0, 80, 240)\n",
    "y_mean, y_std = gp.predict(X[:, None], return_std=True)\n",
    "plt.plot(X, y_mean, 'k', lw=1, zorder=9)\n",
    "plt.fill_between(X, y_mean - y_std, y_mean + y_std,\n",
    "                 alpha=0.2, color='k')\n",
    "print(gp.kernel_)\n",
    "\n",
    "y_samples = gp.sample_y(X[:, None], 5)\n",
    "plt.plot(X, y_samples, lw=0.5, alpha=0.8)\n",
    "\n",
    "plt.plot(xi, y_d, lw=4, alpha=0.3)\n",
    "plt.plot(x_e, y_derr, 'ko', alpha=0.5)\n",
    "plt.plot(x_e, y_derr, 'ko--', alpha=0.2)\n",
    "\n",
    "plt.xlim([0, 60])\n",
    "plt.ylim([-2.5, 2.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " De-trending a timeseries data with a long-term trend makes it easier for the GP regression method to identify the underlying oscillation within our noisy data. As previously mentioned, we don't always need to do this, but it makes the optimization step much easier, as we can focus on modelling the periodic motion and the observational noise in the data. However, it has to be mentioned that de-trending the data does not necessarily make the GP regression more accurate, but it makes the periodicity analysis more straightforward.\n",
    " \n",
    " The resulting period $T = 10$ minutes is exactly the periodicity in the original sine function, which is impressive especially since we have added observational errors in both $x$ and $y$ dimensions. Of course, it is not always the case that we can *exactly* determine the periodicity of the noisy timeseries, but the method seems to yield consistent results, mostly within $5-10 \\%$ of the ground truth (10 minutes).\n",
    " \n",
    " To further show how good the periodicity estimate is with GP regression method, I have plotted the observed timeseries (black dots) and the ground truth (solid blue) as well as the predicted model (solid orange). The predicted model deviates slightly from the wave function, but remains quite close to the ground truth without noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(15, 5))\n",
    "\n",
    "plt.plot(X, np.sin(X * (2 * np.pi) / 10), lw=5, alpha=0.3)\n",
    "plt.plot(X, y_mean, lw=2, alpha=0.6)\n",
    "\n",
    "plt.plot(x_e, y_derr, 'ko', alpha=0.5)\n",
    "plt.plot(x_e, y_derr, 'ko--', alpha=0.2)\n",
    "\n",
    "plt.xlim([0, 60])\n",
    "#plt.ylim([-2.5, 2.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Results\n",
    "\n",
    " Oscillatory motions of boundary-layer clouds can be seen at multiple scales. Many cumulus clouds can be described as a series of pulsating plumes, and this periodic nature has long been thought to be a crucial factor in understanding the life cycle of moist convection (Malkus, QJR, 1952; Zhao and Austin, JAS, 2005a, 2005b; Heus et al., JGR, 2009). The cloud size distribution, a macro-scale property of cloud fields, has also been observed to oscillate over time; clouds grow larger and deeper as smaller plumes aggregate, which is followed by a breakup of larger clouds and an abundance of smaller clouds (Feingold et al., JGR, 2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Oscillations in Cloud Size Distribution \n",
    "\n",
    " First, we examine the observations of oscillating size distribution in a shallow cumulus field according to Feingold et al. (2017). In the literature, it is well known that the cloud size distribution can be well described by a negative power law distribution as a function of cloud size $a$, or $$P(a) = A a^b,$$  where $P(a)$ is the number of clouds between cloud area $a$ and $d\\,a$ in units of m$^2$.\n",
    " \n",
    " Feingold et al. (2017) report that the size distribution parameters oscillate at two distinctive periods, one at $\\approx 80$ min and one at $\\approx 15$ min, using the Fourier spectral analysis.\n",
    " \n",
    " The following is the result of running the Fourier spectral analysis on our BOMEX data; as reported by Feingold et al. (2017), we do observe two peaks at a periodicity of $\\approx 80$ min and one at $\\approx 15$ min, but we also see another peak at $\\approx 45$ min. At the moment at least, it is not clear if it relates to some physical attributes of the cloud size distribution or to some convective timescales inherent in BOMEX case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('../png/plot_fft.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In order to study the oscillations in the cloud size distribution, we use our BOMEX dataset to obtain the size distribution at each timestep and apply Gaussian process regression method. The following is a log-log plot of the cloud size distribution at 5 hours into simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image('../png/get_cloud_size_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef_: -0.82337, int_: 2.65854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since we are working on a log-log plot, we estimated the slope and the intercept of the cloud size distribution, which gives us $b$ (coefficient/slope) and $A$ (intercept) for the power law relationship.\n",
    " \n",
    " The slope and the intercept is estimated by a ridge regression method.\n",
    " \n",
    " It has to be noted that due to the nature of the analysis, there is a lot of variance involved in preparing the timeseries dataset. There are uncertainties in measuring the size of the individual cloud, in determining the right bin size to come up with the cloud size distribution, and in estimating the slope (and intercept) of that distribution. As a result, we expect that the observed timeseries will be very noisy. We could test the sensitivity of some parameters (especially the bin size and the weighting function) in the future.\n",
    " \n",
    " We repeated the regression process for our 3-hour dataset, and plotted the timeseries of the slope $b$ for the cloud size distribution during that period. I have also repeated the following analysis for the intercept $A$, and confirmed that the two variables are highly correlated to each other, but the results for the intercept $A$ is skipped for brevity. We will focus on the oscillatory nature of the slope of the cloud size distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('../png/cloud_slope_timeseries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we can see from the timeseries plot of (the slope of) the cloud size distribution, it is not immediately obvious if the slope of the cloud size distribution has any consistent oscillatory tendencies. Still, that was also the case in the sample wave function in Section 2, so it might be worth trying to use the GP regression method to detect the periodicity in the noisy data.\n",
    " \n",
    " As we have already done in Section 2, I have de-trended the timeseries data above and used *scikit-learn* to apply Gaussian process regression method. Knowing that we have just de-trended the timeseries, I used the *rational quadratic* kernel to account for the local variation, and used two periodic kernels to account for the two periods seen in the Fourier spectral diagram. I have also tested using three for the smallest timescale, most likely corresponding to the eddy turnover timescale at $15$ minutes, but it does not seem to affect the log-marginal likelyhood. So we will ignore it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image('../png/plot_slope_timeseries_BOMEX.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.00316**2 * RBF(length_scale=1e+05) \n",
    "+ 0.0339**2 * RationalQuadratic(alpha=0.884, length_scale=2.31) \n",
    "+ 0.557**2 * WhiteKernel(noise_level=0.000311) \n",
    "+ 0.00316**2 * ExpSineSquared(length_scale=245, periodicity=77.9) \n",
    "+ 0.0195**2 * ExpSineSquared(length_scale=1.04, periodicity=47.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We have added the SE kernel (RBF in *scikit-learn*) as after a few iterations of hyperparameter optimization, it became evident that GP regression was insisting on a long-term trend in the timeseries. This is most likely because the de-trending algorithm isn't aggressive enough. We can probably do better with a custom de-trending function, but for now, simply adding a very smooth, long-term trend to the kernel seems to resolve the issue.\n",
    " \n",
    " As we can see from the hyperparameters of the posterier distribution, the GP regression method seems to converge towards a periodicity at $77.9$ minutes and another at $47.1$ minutes. We also observe that adding a periodic covariance function to account for the $15$-minute oscillation (according to the eddy turnover timescale) gives a periodicity of $16$ minutes, which is not shown for brevity.\n",
    " \n",
    " The former periodicity seems to correspond well to the periodicity of roughly $80$ minutes reported in Feingold et al. (2017). However, it is clear that there is another underlying oscillation in our timeseries data at $\\approx 45$ minutes, although it is not obvious as to where it is coming from. \n",
    " \n",
    " At this point, we can try to visualize the underlying oscillatory motions by *forcing* the GP priors to be very smooth functions (using the SE kernel) which are governed mainly by the periodic covariance function. This is not meant to be a regression step, but merely for the sake of visualization, as it helps us see how good the estimated periodic oscillation really is against noisy observations.\n",
    " \n",
    " The following figures show the result of such psudo-regression using smooth periodic kernels on our timeseries data. The prior periodicities were set roughly ($T = 45$ minutes and $T = 75$ minutes, respectively) but they quickly converged towards the properly estimated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image('../png/plot_slope_timeseries_45min.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF(length_scale=523) \n",
    "+ WhiteKernel(noise_level=0.00103) \n",
    "+ ExpSineSquared(length_scale=47.9, periodicity=46.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('../png/plot_slope_timeseries_75min.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF(length_scale=1e+05) \n",
    "+ WhiteKernel(noise_level=0.0011) \n",
    "+ ExpSineSquared(length_scale=48.5, periodicity=76.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is not quite obvious as to which estimate is *right*, especially because the log-marginal likelihood values are both quite similar ($\\approx 350$). Perhaps it is because we do not have a long enough timeseries data, as in Feingold et al. (2017), the authors observed the changes in the cloud size distribution over a 6-hour period. Perhaps there is indeed a mechanism that is driving the changes in the cloud size distribution over this $45$-minute timespan, although we do not know what it might be.\n",
    " \n",
    " It should be noted, however, that the short-period oscillation predicts that even for this de-trended data, the cloud size distribution will fall rapidly over time. This is indeed the case in BOMEX (*cf.* Figure 9 in Feingold et al. (2017)), and repeating this analysis for a longer timeseries will definitely help us come up with a better periodicity estimate.\n",
    " \n",
    " This would give us an interesting insight in the development of macroscopic as well as microscopic properties of the cloud field. As we have seen before, the macroscopic properties of the cloud field (the slope of the cloud size distribution in this case) can be used to model the microscopic properties of the individual clouds in the domain (mass flux $\\mathcal{M}$ and entrainment rate $\\mathcal{E}$), as shown below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. References\n",
    "\n",
    "Feingold, G., J. Balsells, F. Glassmeier, T. Yamaguchi, J. Kazil, and A. McComiskey, 2017: Analysis of albedo versus cloud fraction relationships in liquid water clouds using heuristic models and large eddy simulation.J. Geophys. Res. Atmos,122, 70867102, doi:10.1002/2017JD026467. \n",
    "\n",
    "Gaussian process regression with scikit-learn: http://scikit-learn.org/stable/modules/gaussian_process.html\n",
    "\n",
    "Khairoutdinov, M. F. and D. A Randall: 2003  Cloud resolving modeling of the ARM summer 1997 IOP: model formulation, results, uncertainties, and sensitivities.  J. Atmos. Sci.,  60, 607-625.\n",
    "\n",
    "Rasmussen, C. E. and C. K. I. Williams, 2006: Gaussian processes for machine learning, MIT Press \n",
    "http://www.gaussianprocess.org/gpml/chapters/RW.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
